{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Classification Using NLP\n",
    "\n",
    "# Business Understanding\n",
    "\n",
    "## Introduction\n",
    "ElecTech is a leading digital retailer of high-end consumer electronics, specializing in Apple and Google products. In today’s fast-paced tech market, consumer opinions on social media platforms such as Twitter often provide early insights into product success or potential issues. However, the massive volume of social media chatter, including news, specifications, and casual commentary, creates significant noise. Manual monitoring is impractical and inefficient.\n",
    "\n",
    "To address this challenge, ElecTech requires an automated **Sentiment Triage Pipeline** that classifies tweets into Positive, Negative, or Neutral categories. By filtering out irrelevant neutral chatter, the **marketing and inventory team** can quickly identify emerging consumer trends, allowing them to mitigate potential negative publicity or capitalize on positive sentiment.\n",
    "\n",
    "In conclusion, transforming raw social media data into actionable insights will help ElecTech optimize inventory decisions, enhance marketing strategies, and maintain a competitive edge in the electronics market.\n",
    "\n",
    "## Problem Statement\n",
    "ElecTech faces a critical challenge in tracking consumer sentiment for Apple and Google products due to the overwhelming volume of social media posts. Most tweets are neutral, such as news headlines or product specifications, which provide little actionable value. Without an automated system, the marketing and inventory teams risk missing early warning signals of product issues or failing to capitalize on positive consumer trends.\n",
    "\n",
    "The goal is to build a multiclass NLP classifier that accurately categorizes tweets as Positive, Negative, or Neutral, enabling the company to proactively respond to shifts in consumer sentiment and make informed business decisions.\n",
    "\n",
    "## Objectives\n",
    "1. **Automate Sentiment Classification:** Build a machine learning model to classify tweets into Positive, Negative, or Neutral categories.\n",
    "2. **Support Business Decisions:** Identify emerging consumer trends to optimize inventory levels and guide marketing strategies.\n",
    "3. **Filter Noise:** Reduce the impact of neutral, non-actionable tweets to highlight meaningful consumer feedback.\n",
    "4. **Enable Scalability and Reproducibility:** Develop a pipeline that can handle large volumes of tweets and be reused or updated in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "The dataset  contains tweets about Apple and Google products. Each row represents a single tweet with the following main columns:\n",
    "\n",
    "- `tweet_text`: the content of the tweet  \n",
    "- `emotion_in_tweet_is_directed_at`: the brand product at which the tweet is about\n",
    "- `is_there_an_emotion_directed_at_a_brand_or_product` : the labeled sentiment of the tweet (Negative emotion , Positive, No emotion)\n",
    "\n",
    "Understanding the structure, quality, and distribution of this data is critical before moving to preprocessing and modeling.\n",
    "\n",
    "Below we shall load and inspect the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283ff809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading dataset\n",
    "df = pd.read_csv('DATA\\judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377c020",
   "metadata": {},
   "source": [
    "## Data Quality Checks\n",
    "We will then assess key data quality aspects: shape, data types, completeness, uniqueness, uniformity, consistency, and validity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1abdee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ce7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9093, 3)\n",
      "\n",
      "Column data types:\n",
      " tweet_text                         object\n",
      "emotion_in_tweet_is_directed_at    object\n",
      "sentiment                          object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      " tweet_text                            1\n",
      "emotion_in_tweet_is_directed_at    5802\n",
      "sentiment                             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 22\n",
      "\n",
      "Invalid sentiment labels (if any): [\"i can't tell\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Rename sentiment column for clarity\n",
    "df.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'}, inplace=True)\n",
    "\n",
    "# 2. Shape of data\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# 3. Data types\n",
    "print(\"\\nColumn data types:\\n\", df.dtypes)\n",
    "\n",
    "# 4. Completeness: missing values\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "\n",
    "# Heatmap for missing values\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Uniqueness: duplicates\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# 6. Uniformity / consistency for categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda x: x.str.strip().str.lower() if x.dtype=='object' else x)\n",
    "\n",
    "# 7. Validity / Accuracy for sentiment\n",
    "valid_sentiments = ['negative emotion','positive emotion','no emotion toward brand or product']\n",
    "invalid_sentiments = df.loc[~df['sentiment'].isin(valid_sentiments), 'sentiment'].unique()\n",
    "print(\"\\nInvalid sentiment labels (if any):\", invalid_sentiments)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a4391d",
   "metadata": {},
   "source": [
    "## Observations and Cleaning Decisions\n",
    "\n",
    "We loaded the dataset `judge-1377884607_tweet_product_company.csv` and inspected its structure, completeness, uniqueness, and validity.\n",
    "\n",
    "1. **Shape and Data Types**  \n",
    "   The dataset contains 9,093 rows and 3 columns:\n",
    "   - `tweet_text` (object): the content of the tweet  \n",
    "   - `emotion_in_tweet_is_directed_at` (object): the product/brand the tweet refers to  \n",
    "   - `sentiment` (object): the labeled sentiment of the tweet  \n",
    "\n",
    "2. **Missing Values**  \n",
    "   - The `tweet_text` column has **1 missing value**. We will drop this row because a tweet without text cannot be used for NLP modeling.  \n",
    "   - The `emotion_in_tweet_is_directed_at` column has **5,802 missing values**. We will **not drop these rows** because this column is **optional metadata** and not required for the sentiment classification task. Dropping them would unnecessarily reduce our dataset size by over 60%, which could hurt model training.  \n",
    "   - The `sentiment` column has no missing values.\n",
    "\n",
    "3. **Duplicates**  \n",
    "   - There are **41 duplicate rows** in the dataset. These will be dropped to prevent the model from learning repetitive data.  \n",
    "\n",
    "4. **Uniformity / Consistency**  \n",
    "   - All categorical columns were converted to lowercase and stripped of whitespace to ensure consistency. This prevents issues where the same label is written differently (e.g., `'Positive Emotion'` vs `'positive emotion'`).  \n",
    "\n",
    "5. **Validity / Accuracy of Sentiment Labels**  \n",
    "   - The `sentiment` column contains the following valid labels:  \n",
    "     `negative emotion`, `positive emotion`, `no emotion toward brand or product`  \n",
    "   - There is **1 invalid label**: `\"i can't tell\"`. \n",
    "   \n",
    "   Which will be dropped:This is because \"i can't tell\" is ambiguous and does not provide clear sentiment information for training the NLP model. Keeping it could introduce noise and reduce model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425cbd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no emotion toward brand or product    5389\n",
       "positive emotion                      2978\n",
       "negative emotion                       570\n",
       "i can't tell                           156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61dd800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (8895, 3)\n",
      "\n",
      "Sentiment distribution after cleaning:\n",
      "no emotion toward brand or product    5360\n",
      "positive emotion                      2966\n",
      "negative emotion                       569\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning: Applying Decisions\n",
    "\n",
    "# 1. Drop rows with missing tweet_text\n",
    "df = df.dropna(subset=['tweet_text'])\n",
    "\n",
    "# 2. Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 3. Drop rows with invalid sentiment (\"i can't tell\")\n",
    "valid_sentiments = ['negative emotion', 'positive emotion', 'no emotion toward brand or product']\n",
    "df = df[df['sentiment'].isin(valid_sentiments)]\n",
    "\n",
    "# 4. Reset index after cleaning\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Check dataset shape after cleaning\n",
    "print(\"Dataset shape after cleaning:\", df.shape)\n",
    "\n",
    "#  check sentiment counts\n",
    "print(\"\\nSentiment distribution after cleaning:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba191a9f",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In this stage, we prepare the tweet text for NLP modeling. The main steps include:\n",
    "\n",
    "1. **Text Cleaning**: Remove URLs, mentions, hashtags, special characters, and numbers.\n",
    "2. **Lowercasing**: Convert all text to lowercase for uniformity.\n",
    "3. **Tokenization & Stopwords Removal**: Split tweets into individual words and remove common words that do not carry sentiment meaning.\n",
    "4. **Lemmatization**: Reduce words to their base form (e.g., \"running\" → \"run\") to improve model generalization.\n",
    "5. **Label Encoding**: Convert sentiment labels (Positive, Negative, Neutral) into numeric form for modeling.\n",
    "6. **Final Dataset Ready for Modeling**: Cleaned text in `cleaned_tweet`, target labels as numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396c091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ELITEBOOK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ELITEBOOK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'negative emotion': 0, 'no emotion toward brand or product': 1, 'positive emotion': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>g iphone hr tweeting dead need upgrade plugin ...</td>\n",
       "      <td>negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>wait also sale</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>hope year festival isnt crashy year iphone app</td>\n",
       "      <td>negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>great stuff fri marissa mayer google tim oreil...</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...   \n",
       "3  @sxsw i hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...   \n",
       "\n",
       "                                       cleaned_tweet         sentiment  \\\n",
       "0  g iphone hr tweeting dead need upgrade plugin ...  negative emotion   \n",
       "1  know awesome ipadiphone app youll likely appre...  positive emotion   \n",
       "2                                     wait also sale  positive emotion   \n",
       "3     hope year festival isnt crashy year iphone app  negative emotion   \n",
       "4  great stuff fri marissa mayer google tim oreil...  positive emotion   \n",
       "\n",
       "   sentiment_label  \n",
       "0                0  \n",
       "1                2  \n",
       "2                2  \n",
       "3                0  \n",
       "4                2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP Data Preparation\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean tweet text\n",
    "def clean_tweet(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Rejoin to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply cleaning function to tweet_text\n",
    "df['cleaned_tweet'] = df['tweet_text'].apply(clean_tweet)\n",
    "\n",
    "# Encode sentiment labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment_label'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Mapping for reference\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "# Show first few rows of cleaned data\n",
    "df[['tweet_text', 'cleaned_tweet', 'sentiment', 'sentiment_label']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1b67d",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "In this section, we will develop machine learning models that can learn patterns from the prepared tweet text\n",
    "and predict sentiment toward brands or products.\n",
    "\n",
    "We begin with a **baseline NLP model** that combines:\n",
    "- Bag-of-Words text representation using **CountVectorizer**\n",
    "- A probabilistic classifier, **Multinomial Naive Bayes**\n",
    "\n",
    "This baseline provides a simple, interpretable reference point against which more advanced models\n",
    "can later be compared.\n",
    "\n",
    "\n",
    "### 1. Baseline Model: CountVectorizer + Multinomial Naive Bayes\n",
    "\n",
    "We selected **Multinomial Naive Bayes (MNB)** as our first model because:\n",
    "\n",
    "- It is well-suited for **text classification** tasks\n",
    "- It performs efficiently on **word count features**\n",
    "- It scales well to large vocabularies\n",
    "- It provides a strong baseline despite its simplifying assumptions\n",
    "\n",
    "To convert raw text into numerical features, we use **CountVectorizer**, which transforms each tweet\n",
    "into a vector representing the frequency of words appearing in the text.\n",
    "\n",
    "Both steps are combined into a single **scikit-learn Pipeline** to ensure:\n",
    "- clean, reproducible preprocessing\n",
    "- prevention of data leakage\n",
    "- consistent transformation during training and testing\n",
    "\n",
    "\n",
    "Below we define Feature(X) and Target(y) variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3093fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix and target vector\n",
    "X = df['cleaned_tweet']\n",
    "y = df['sentiment_label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6c101",
   "metadata": {},
   "source": [
    "### Class Distribution Check\n",
    "\n",
    "Before splitting the data, we examine the distribution of sentiment classes.\n",
    "This helps confirm whether class imbalance exists and informs our choice of\n",
    "modeling strategy.\n",
    "\n",
    "In imbalanced datasets, random splitting can distort class proportions,\n",
    "leading to biased evaluation results. To mitigate this, we apply stratified\n",
    "sampling during the train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8798a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no emotion toward brand or product    60.258572\n",
       "positive emotion                      33.344576\n",
       "negative emotion                       6.396852\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class distribution before splitting\n",
    "df['sentiment'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7826e1",
   "metadata": {},
   "source": [
    "We  split the dataset into training and testing sets using an **80/20 split**.\n",
    "\n",
    "Because the dataset contains **imbalanced sentiment classes**, we apply **stratified sampling**\n",
    "to preserve the original class distribution in both sets.\n",
    "\n",
    "A fixed random state is used to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0283a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c022cd",
   "metadata": {},
   "source": [
    "### Building the Pipeline\n",
    "\n",
    "With the data split into training and testing sets, we now build the modeling pipeline.\n",
    "\n",
    "\n",
    "The pipeline consists of two sequential steps:\n",
    "\n",
    "1. **CountVectorizer**\n",
    "   - Converts text into a bag-of-words representation\n",
    "   - Learns the vocabulary from the training data only\n",
    "\n",
    "2. **Multinomial Naive Bayes**\n",
    "   - Learns class-conditional word distributions\n",
    "   - Predicts sentiment based on posterior probabilities\n",
    "\n",
    "Using a pipeline ensures that all preprocessing steps are applied consistently and correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252e1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d5e2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipeline_nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0679e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment labels for the test set\n",
    "y_pred = pipeline_nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8f6fe",
   "metadata": {},
   "source": [
    "### Model 2 : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865d1d0",
   "metadata": {},
   "source": [
    "### Model 3 :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
